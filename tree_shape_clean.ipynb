{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree, TreeStyle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(file_path, index):\n",
    "    with open(file_path, 'r') as file:\n",
    "        parent_data = file.readlines()[index].strip().split()\n",
    "\n",
    "    node_dict = {}\n",
    "\n",
    "    for idx, parent_id in enumerate(parent_data, start=1):\n",
    "        if idx not in node_dict:\n",
    "            node_dict[idx] = Tree(name=str(idx))\n",
    "        if int(parent_id) not in node_dict:\n",
    "            node_dict[int(parent_id)] = Tree(name=str(parent_id))\n",
    "\n",
    "        node_dict[int(parent_id)].add_child(node_dict[idx])\n",
    "    \n",
    "    return node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_mutations_L(file_path, index):\n",
    "    with open(file_path, 'r') as file:\n",
    "        final_distribution = file.readlines()[index].strip().split()\n",
    "    \n",
    "    return [str(num) for num in final_distribution]\n",
    "\n",
    "def get_final_mutations(file_path, index):\n",
    "    with open(file_path, 'r') as file:\n",
    "        final_distribution = file.readlines()[index].strip().split()\n",
    "    \n",
    "    return set([str(num) for num in final_distribution])\n",
    "\n",
    "def sample_final_mutations(final_distribution, k):\n",
    "    return set(random.sample(final_distribution, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_nodes(tree, nodes):\n",
    "    # nodes = [str(num) for num in nodes]\n",
    "    necessary_nodes = set(nodes)\n",
    "    for node_id in nodes:\n",
    "        current_node = tree.search_nodes(name=str(node_id))[0]\n",
    "        while current_node.up: \n",
    "            necessary_nodes.add(current_node.up.name)\n",
    "            current_node = current_node.up\n",
    "    return necessary_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def count_non_empty_lines(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return 0\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        return sum(1 for line in f if line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coalescence_time(tree, samples):\n",
    "    samples = set(samples)\n",
    "    if len(samples) <= 1: return 0\n",
    "    ancestor = tree.get_common_ancestor(samples)\n",
    "    max_distance = max(ancestor.get_distance(tree & sample) for sample in samples)\n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_coalescence(output_file, checkpoint_interval=50):\n",
    "    ks = [6, 10]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 50 # Number of trees with same parameters\n",
    "    num_samples = 100  # Number of samples per file\n",
    "    iterations = 200 # Number of coalescence calculations per sample\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'mean_coalescence_time_20': [], 'variance_coalescence_time_20': [],\n",
    "                'mean_coalescence_time_40': [], 'variance_coalescence_time_40': [],\n",
    "                'mean_coalescence_time_60': [], 'variance_coalescence_time_60': [],\n",
    "                'mean_coalescence_time_80': [], 'variance_coalescence_time_80': [],\n",
    "                'mean_coalescence_time_100': [], 'variance_coalescence_time_100': [],}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "\n",
    "                        tree_path = f\"result_12.11/{k}_regular_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        final_path = f\"result_12.11/{k}_regular_{i}_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree files\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate the coalescence time\n",
    "                        sample_coalescence_times = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "                            distribution = get_final_mutations_L(final_path, sample_idx)\n",
    "                            path = find_all_nodes(tree, get_final_mutations(final_path, sample_idx))\n",
    "                            tree.prune(path)\n",
    "                            coalescence_times = []\n",
    "                            for _ in range(iterations):\n",
    "                                try:\n",
    "                                    coalescence_times.append(get_coalescence_time(tree, random.sample(distribution, 2)))\n",
    "                                except:\n",
    "                                    pass\n",
    "                            sample_avg_time = np.mean(coalescence_times)\n",
    "                            sample_coalescence_times.append(sample_avg_time)\n",
    "                            # print(sample_idx)\n",
    "\n",
    "                        mean_coalescence_time = np.mean(sample_coalescence_times)\n",
    "                        variance_coalescence_time = np.var(sample_coalescence_times)\n",
    "\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        data['mean_coalescence_time_20'].append(np.mean(sample_coalescence_times[:min(20, num_samples)]))\n",
    "                        data['variance_coalescence_time_20'].append(np.var(sample_coalescence_times[:min(20, num_samples)]))\n",
    "\n",
    "                        data['mean_coalescence_time_40'].append(np.mean(sample_coalescence_times[:min(40, num_samples)]))\n",
    "                        data['variance_coalescence_time_40'].append(np.var(sample_coalescence_times[:min(40, num_samples)]))\n",
    "\n",
    "                        data['mean_coalescence_time_60'].append(np.mean(sample_coalescence_times[:min(60, num_samples)]))\n",
    "                        data['variance_coalescence_time_60'].append(np.var(sample_coalescence_times[:min(60, num_samples)]))\n",
    "\n",
    "                        data['mean_coalescence_time_80'].append(np.mean(sample_coalescence_times[:min(80, num_samples)]))\n",
    "                        data['variance_coalescence_time_80'].append(np.var(sample_coalescence_times[:min(80, num_samples)]))\n",
    "\n",
    "                        data['mean_coalescence_time_100'].append(np.mean(sample_coalescence_times[:min(100, num_samples)]))\n",
    "                        data['variance_coalescence_time_100'].append(np.var(sample_coalescence_times[:min(100, num_samples)]))\n",
    "\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "calculate_coalescence(\"coalescence_regular_50_2.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sackin_index(tree):\n",
    "    leaves = tree.get_leaves()  \n",
    "    total_depth = sum(leaf.get_distance(tree) for leaf in leaves)  \n",
    "    num_leaves = len(leaves)  \n",
    "    if num_leaves > 1:\n",
    "        normalized_index = total_depth / (0.5 * num_leaves * (num_leaves + 1) - 1)\n",
    "    else:\n",
    "        normalized_index = 0  \n",
    "    \n",
    "    # # tree depth\n",
    "    # tree_depth = max(leaf.get_distance(tree) for leaf in leaves) if leaves else 0\n",
    "    \n",
    "    # # tree width\n",
    "    # levels = {}\n",
    "    # for leaf in leaves:\n",
    "    #     level = leaf.get_distance(tree, topology_only=True)\n",
    "    #     if level not in levels:\n",
    "    #         levels[level] = 0\n",
    "    #     levels[level] += 1\n",
    "    # tree_width = max(levels.values()) if levels else 0\n",
    "\n",
    "    return normalized_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sackin(output_file, checkpoint_interval=50):\n",
    "    ks = [1, 6, 11, 15, 18]\n",
    "    mus = [1, 0.1, 0.01, 0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 1\n",
    "    num_samples = 100  # Number of samples per file\n",
    "\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'sackin': [], 'sackin_variance': []}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "                        \n",
    "                        tree_path = f\"result_12.4/test_{k}_mu{mu}_s{s}_tree.txt\"\n",
    "                        final_path = f\"result_12.4/test_{k}_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree file\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate Sackin index\n",
    "                        sackinL = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "                            distribution = get_final_mutations_L(final_path, sample_idx)\n",
    "                            path = find_all_nodes(tree, get_final_mutations(final_path, sample_idx))\n",
    "                            tree.prune(path)\n",
    "                            sackin_index = get_sackin_index(tree)\n",
    "                            sackinL.append(sackin_index)\n",
    "                            # print(sample_idx)\n",
    "\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        data['sackin'].append(np.mean(sackinL))\n",
    "                        data['sackin_variance'].append(np.var(sackinL))\n",
    "\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "calculate_sackin(\"sackin_geoN.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Tree Balance Index (J1): 0.004066544747433984\n"
     ]
    }
   ],
   "source": [
    "from ete3 import Tree\n",
    "import numpy as np\n",
    "\n",
    "def compute_subtree_sizes(node):\n",
    "    \"\"\"\n",
    "    Compute S_i (total subtree size including root) and S*_i (excluding root).\n",
    "    Assigns these values to the node attributes.\n",
    "    \"\"\"\n",
    "    if node.is_leaf():\n",
    "        node.S_i = 1  # A leaf has size 1 (itself)\n",
    "        node.S_star_i = 0  # No subtree without root\n",
    "        return 1, 0  \n",
    "\n",
    "    subtree_size = 1  # Count itself\n",
    "    child_sizes = []\n",
    "\n",
    "    for child in node.children:\n",
    "        child_s, _ = compute_subtree_sizes(child)\n",
    "        child_sizes.append(child_s)\n",
    "        subtree_size += child_s  # Accumulate child subtree sizes\n",
    "    \n",
    "    S_star_i = subtree_size - 1  # Exclude root itself\n",
    "    \n",
    "    # Store values as attributes inside the node\n",
    "    node.S_i = subtree_size\n",
    "    node.S_star_i = S_star_i\n",
    "    node.child_sizes = child_sizes  # Store sizes of children\n",
    "\n",
    "    return subtree_size, S_star_i\n",
    "\n",
    "\n",
    "def compute_balance_scores(node):\n",
    "    if node.is_leaf() or len(node.children) < 2:\n",
    "        node.W_i = 0\n",
    "        return 0\n",
    "    \n",
    "    p_ij = np.array([child.S_i / node.S_star_i for child in node.children])\n",
    "    \n",
    "    W_i_1 = -np.sum(p_ij * np.log(p_ij) / np.log(len(node.children)))\n",
    "    \n",
    "    node.W_i = W_i_1\n",
    "    return W_i_1\n",
    "\n",
    "def compute_normalized_balance_index(root):\n",
    "    \"\"\"\n",
    "    Compute the normalized tree balance index J^1.\n",
    "    \"\"\"\n",
    "    internal_nodes = [n for n in root.traverse() if not n.is_leaf()]\n",
    "    \n",
    "    S_star_sum = sum(n.S_star_i for n in internal_nodes)\n",
    "    weighted_sum = sum(n.S_star_i / n.S_i * n.W_i for n in internal_nodes)\n",
    "    \n",
    "    return weighted_sum / S_star_sum if S_star_sum > 0 else 0\n",
    "\n",
    "k = 3\n",
    "i = 0\n",
    "mu = 0.001\n",
    "s = 0\n",
    "tree_path = f\"graphs/results1/{k}_regular_graph/{k}_regular_graph_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "final_path = f\"graphs/results1/{k}_regular_graph/{k}_regular_graph_{i}_mu{mu}_s{s}_list.txt\"\n",
    "tree_dict = build_tree(tree_path, 0)\n",
    "\n",
    "\n",
    "# Assuming root node is labeled as '1'\n",
    "root = tree_dict[0]\n",
    "\n",
    "# Step 1: Compute sizes\n",
    "compute_subtree_sizes(root)\n",
    "\n",
    "# Step 2: Compute balance scores\n",
    "for node in root.traverse():\n",
    "    compute_balance_scores(node)\n",
    "\n",
    "# Step 3: Compute the normalized balance index\n",
    "J1 = compute_normalized_balance_index(root)\n",
    "\n",
    "print(\"Normalized Tree Balance Index (J1):\", J1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  25%|██▌       | 50/200 [06:46<22:34,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  50%|█████     | 100/200 [13:36<13:04,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  75%|███████▌  | 150/200 [20:17<06:41,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times: 100%|██████████| 200/200 [26:55<00:00,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 200\n",
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_coalescence_df_with_progress_and_saves(output_file, checkpoint_interval=50):\n",
    "    \"\"\"Calculate mean and variance of coalescence times with progress bar and periodic saves.\n",
    "\n",
    "    Args:\n",
    "        output_file (str): Path to the final output file (Pandas DataFrame saved as a pickle file).\n",
    "        checkpoint_interval (int): Number of iterations after which to save a temporary file.\n",
    "    \"\"\"\n",
    "    ks = [3, 4, 6, 10]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 50\n",
    "    num_samples = 100  # Number of samples per file\n",
    "    iterations = 200 # Number of coalescence calculations per sample\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'Js': [], 'variance_Js': [],}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    # Calculate the total number of combinations for the progress bar\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "                        # Skip if this combination has already been completed\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "\n",
    "                        tree_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        final_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        # Check if paths exist; skip if they don't\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree file (assuming the sample index isn't needed)\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate the coalescence time for each sample in the file\n",
    "                        Js = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "\n",
    "                            compute_subtree_sizes(tree)\n",
    "\n",
    "                            for node in tree.traverse():\n",
    "                                compute_balance_scores(node)\n",
    "\n",
    "                            J1 = compute_normalized_balance_index(tree)\n",
    "\n",
    "                            Js.append(J1)\n",
    "                            # print(sample_idx)\n",
    "\n",
    "                        # Calculate mean and variance across all samples\n",
    "                        mean_Js = np.mean(Js)\n",
    "                        variance_Js = np.var(Js)\n",
    "\n",
    "                        # Append results to the data dictionary\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        data['Js'].append(np.mean(mean_Js))\n",
    "                        data['variance_Js'].append(np.var(mean_Js))\n",
    "\n",
    "\n",
    "                        # Update progress bar after each combination\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        # Save a checkpoint after every `checkpoint_interval` iterations\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    # Final save: Create a DataFrame and save as the final file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "# Call the function to write the stats to a pandas DataFrame file with checkpointing\n",
    "calculate_coalescence_df_with_progress_and_saves(\"Js_regular_50.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>mu</th>\n",
       "      <th>s</th>\n",
       "      <th>repetition</th>\n",
       "      <th>Js</th>\n",
       "      <th>variance_Js</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      k     mu    s  repetition        Js  variance_Js\n",
       "0     3  0.001  0.1           0  0.000323          0.0\n",
       "1     3  0.001  0.1           1  0.000327          0.0\n",
       "2     3  0.001  0.1           2  0.000328          0.0\n",
       "3     3  0.001  0.1           3  0.000331          0.0\n",
       "4     3  0.001  0.1           4  0.000335          0.0\n",
       "..   ..    ...  ...         ...       ...          ...\n",
       "195  10  0.001  0.1          45  0.000242          0.0\n",
       "196  10  0.001  0.1          46  0.000242          0.0\n",
       "197  10  0.001  0.1          47  0.000243          0.0\n",
       "198  10  0.001  0.1          48  0.000250          0.0\n",
       "199  10  0.001  0.1          49  0.000248          0.0\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df31 = pd.read_pickle(\"Js_regular_50.pkl\")\n",
    "df31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
