{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'HOME' not in os.environ and 'USERPROFILE' in os.environ:\n",
    "    os.environ['HOME'] = os.environ['USERPROFILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(file_path, index):\n",
    "    with open(file_path, 'r') as file:\n",
    "        parent_data = file.readlines()[index].strip().split()\n",
    "\n",
    "    node_dict = {}\n",
    "\n",
    "    for idx, parent_id in enumerate(parent_data, start=1):\n",
    "        if idx not in node_dict:\n",
    "            node_dict[idx] = Tree(name=str(idx))\n",
    "        if int(parent_id) not in node_dict:\n",
    "            node_dict[int(parent_id)] = Tree(name=str(parent_id))\n",
    "\n",
    "        node_dict[int(parent_id)].add_child(node_dict[idx])\n",
    "    \n",
    "    return node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_mutations_L(file_path, index):\n",
    "    with open(file_path, 'r') as file:\n",
    "        final_distribution = file.readlines()[index].strip().split()\n",
    "    \n",
    "    return [str(num) for num in final_distribution]\n",
    "\n",
    "def get_final_mutations(file_path, index):\n",
    "    with open(file_path, 'r') as file:\n",
    "        final_distribution = file.readlines()[index].strip().split()\n",
    "    \n",
    "    return set([str(num) for num in final_distribution])\n",
    "\n",
    "def sample_final_mutations(final_distribution, k):\n",
    "    return set(random.sample(final_distribution, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_nodes(tree, nodes):\n",
    "    # nodes = [str(num) for num in nodes]\n",
    "    necessary_nodes = set(nodes)\n",
    "    for node_id in nodes:\n",
    "        current_node = tree.search_nodes(name=str(node_id))[0]\n",
    "        while current_node.up: \n",
    "            necessary_nodes.add(current_node.up.name)\n",
    "            current_node = current_node.up\n",
    "    return necessary_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def count_non_empty_lines(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return 0\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        return sum(1 for line in f if line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coalescence_time(tree, samples):\n",
    "    samples = set(samples)\n",
    "    if len(samples) <= 1: return 0\n",
    "    ancestor = tree.get_common_ancestor(samples)\n",
    "    max_distance = max(ancestor.get_distance(tree & sample) for sample in samples)\n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_tree_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m final_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgraphs/result_11.1/geo_1_edges_mu0.001_s0.1_list.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m tree_dict = build_tree(tree_path, \u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mcalculate_tree_metrics\u001b[49m(tree_dict[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'calculate_tree_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "tree_path = f\"graphs/result_11.1/geo_1_edges_mu0.001_s0.1_tree.txt\"\n",
    "final_path = f\"graphs/result_11.1/geo_1_edges_mu0.001_s0.1_list.txt\"\n",
    "\n",
    "tree_dict = build_tree(tree_path, 0)\n",
    "calculate_tree_metrics(tree_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing paths: graphs/result_11.1/geo_0_edges_mu0.001_s0.1_tree.txt, graphs/result_11.1/geo_0_edges_mu0.001_s0.1_list.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times: 100%|██████████| 21/21 [08:18<00:00, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_coalescence(output_file, checkpoint_interval=50):\n",
    "    ks = [\"geo\"]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 21 # Number of trees with same parameters\n",
    "    num_samples = 100  # Number of samples per file\n",
    "    iterations = 200 # Number of coalescence calculations per sample\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'mean_coalescence_time': [], 'variance_coalescence_time': [],}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "\n",
    "                        tree_path = f\"graphs/result_11.1/geo_{i}_edges_mu{mu}_s{s}_tree.txt\"\n",
    "                        final_path = f\"graphs/result_11.1/geo_{i}_edges_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree files\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate the coalescence time\n",
    "                        sample_coalescence_times = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "                            distribution = get_final_mutations_L(final_path, sample_idx)\n",
    "                            path = find_all_nodes(tree, get_final_mutations(final_path, sample_idx))\n",
    "                            tree.prune(path)\n",
    "                            coalescence_times = []\n",
    "                            for _ in range(iterations):\n",
    "                                try:\n",
    "                                    coalescence_times.append(get_coalescence_time(tree, random.sample(distribution, 2)))\n",
    "                                except:\n",
    "                                    pass\n",
    "                            sample_avg_time = np.mean(coalescence_times)\n",
    "                            sample_coalescence_times.append(sample_avg_time)\n",
    "                            # print(sample_idx)\n",
    "\n",
    "                        mean_coalescence_time = np.mean(sample_coalescence_times)\n",
    "                        variance_coalescence_time = np.var(sample_coalescence_times)\n",
    "\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "\n",
    "                        data['mean_coalescence_time'].append(mean_coalescence_time)\n",
    "                        data['variance_coalescence_time'].append(variance_coalescence_time)\n",
    "\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "calculate_coalescence(\"coalescence_geo_20.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sackin_index(tree):\n",
    "    leaves = tree.get_leaves()  \n",
    "    total_depth = sum(leaf.get_distance(tree) for leaf in leaves)  \n",
    "    num_leaves = len(leaves)  \n",
    "    if num_leaves > 1:\n",
    "        normalized_index = total_depth / (0.5 * num_leaves * (num_leaves + 1) - 1)\n",
    "    else:\n",
    "        normalized_index = 0  \n",
    "    \n",
    "    # # tree depth\n",
    "    # tree_depth = max(leaf.get_distance(tree) for leaf in leaves) if leaves else 0\n",
    "    \n",
    "    # # tree width\n",
    "    # levels = {}\n",
    "    # for leaf in leaves:\n",
    "    #     level = leaf.get_distance(tree, topology_only=True)\n",
    "    #     if level not in levels:\n",
    "    #         levels[level] = 0\n",
    "    #     levels[level] += 1\n",
    "    # tree_width = max(levels.values()) if levels else 0\n",
    "\n",
    "    return normalized_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  33%|███▎      | 50/150 [02:31<04:25,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  67%|██████▋   | 100/150 [04:59<02:27,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times: 100%|██████████| 150/150 [07:31<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 150\n",
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_sackin(output_file, checkpoint_interval=50):\n",
    "    # ks = [\"geo\"]\n",
    "    ks = [3, 4, 6]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 50 # Number of trees with same parameters\n",
    "    num_samples = 20  # Number of samples per file\n",
    "\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'sackin': [], 'sackin_variance': []}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "                        \n",
    "                        # tree_path = f\"graphs/result_11.1/geo_{i}_edges_mu{mu}_s{s}_tree.txt\"\n",
    "                        # final_path = f\"graphs/result_11.1/geo_{i}_edges_mu{mu}_s{s}_list.txt\"\n",
    "                        tree_path = f\"graphs/result_5.16/{k}_regular_{i}_m{mu}_s{s}.txt_tree.txt\"\n",
    "                        final_path = f\"graphs/result_5.16/{k}_regular_{i}_m{mu}_s{s}.txt_list.txt\"\n",
    "\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree file\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate Sackin index\n",
    "                        sackinL = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "                            distribution = get_final_mutations_L(final_path, sample_idx)\n",
    "                            path = find_all_nodes(tree, get_final_mutations(final_path, sample_idx))\n",
    "                            tree.prune(path)\n",
    "                            sackin_index = get_sackin_index(tree)\n",
    "                            sackinL.append(sackin_index)\n",
    "                            # print(sample_idx)\n",
    "\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        data['sackin'].append(np.mean(sackinL))\n",
    "                        data['sackin_variance'].append(np.var(sackinL))\n",
    "\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "calculate_sackin(\"sackin_regular_stoch_50.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Tree Balance Index (J1): 0.004066544747433984\n"
     ]
    }
   ],
   "source": [
    "from ete3 import Tree\n",
    "import numpy as np\n",
    "\n",
    "def compute_subtree_sizes(node):\n",
    "    \"\"\"\n",
    "    Compute S_i (total subtree size including root) and S*_i (excluding root).\n",
    "    Assigns these values to the node attributes.\n",
    "    \"\"\"\n",
    "    if node.is_leaf():\n",
    "        node.S_i = 1  # A leaf has size 1 (itself)\n",
    "        node.S_star_i = 0  # No subtree without root\n",
    "        return 1, 0  \n",
    "\n",
    "    subtree_size = 1  # Count itself\n",
    "    child_sizes = []\n",
    "\n",
    "    for child in node.children:\n",
    "        child_s, _ = compute_subtree_sizes(child)\n",
    "        child_sizes.append(child_s)\n",
    "        subtree_size += child_s  # Accumulate child subtree sizes\n",
    "    \n",
    "    S_star_i = subtree_size - 1  # Exclude root itself\n",
    "    \n",
    "    # Store values as attributes inside the node\n",
    "    node.S_i = subtree_size\n",
    "    node.S_star_i = S_star_i\n",
    "    node.child_sizes = child_sizes  # Store sizes of children\n",
    "\n",
    "    return subtree_size, S_star_i\n",
    "\n",
    "\n",
    "def compute_balance_scores(node):\n",
    "    if node.is_leaf() or len(node.children) < 2:\n",
    "        node.W_i = 0\n",
    "        return 0\n",
    "    \n",
    "    p_ij = np.array([child.S_i / node.S_star_i for child in node.children])\n",
    "    \n",
    "    W_i_1 = -np.sum(p_ij * np.log(p_ij) / np.log(len(node.children)))\n",
    "    \n",
    "    node.W_i = W_i_1\n",
    "    return W_i_1\n",
    "\n",
    "def compute_normalized_balance_index(root):\n",
    "    \"\"\"\n",
    "    Compute the normalized tree balance index J^1.\n",
    "    \"\"\"\n",
    "    internal_nodes = [n for n in root.traverse() if not n.is_leaf()]\n",
    "    \n",
    "    S_star_sum = sum(n.S_star_i for n in internal_nodes)\n",
    "    weighted_sum = sum(n.S_star_i / n.S_i * n.W_i for n in internal_nodes)\n",
    "    \n",
    "    return weighted_sum / S_star_sum if S_star_sum > 0 else 0\n",
    "\n",
    "k = 3\n",
    "i = 0\n",
    "mu = 0.001\n",
    "s = 0\n",
    "tree_path = f\"graphs/results1/{k}_regular_graph/{k}_regular_graph_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "final_path = f\"graphs/results1/{k}_regular_graph/{k}_regular_graph_{i}_mu{mu}_s{s}_list.txt\"\n",
    "tree_dict = build_tree(tree_path, 0)\n",
    "\n",
    "\n",
    "# Assuming root node is labeled as '1'\n",
    "root = tree_dict[0]\n",
    "\n",
    "# Step 1: Compute sizes\n",
    "compute_subtree_sizes(root)\n",
    "\n",
    "# Step 2: Compute balance scores\n",
    "for node in root.traverse():\n",
    "    compute_balance_scores(node)\n",
    "\n",
    "# Step 3: Compute the normalized balance index\n",
    "J1 = compute_normalized_balance_index(root)\n",
    "\n",
    "print(\"Normalized Tree Balance Index (J1):\", J1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing paths: graphs/result_11.8/bn_0_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_0_mu0.001_s0.1_list.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times: 100%|██████████| 21/21 [01:22<00:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing paths: graphs/result_11.8/bn_10_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_10_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_11_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_11_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_12_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_12_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_13_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_13_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_14_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_14_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_15_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_15_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_16_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_16_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_17_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_17_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_18_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_18_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_19_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_19_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_20_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_20_mu0.001_s0.1_list.txt\n",
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_coalescence_df_with_progress_and_saves(output_file, checkpoint_interval=50):\n",
    "    \"\"\"Calculate mean and variance of coalescence times with progress bar and periodic saves.\n",
    "\n",
    "    Args:\n",
    "        output_file (str): Path to the final output file (Pandas DataFrame saved as a pickle file).\n",
    "        checkpoint_interval (int): Number of iterations after which to save a temporary file.\n",
    "    \"\"\"\n",
    "    ks = [\"bn\"]#[3, 4, 6, 10]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 21\n",
    "    num_samples = 100  # Number of samples per file\n",
    "    iterations = 200 # Number of coalescence calculations per sample\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'Js': [], 'variance_Js': [],}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    # Calculate the total number of combinations for the progress bar\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "                        # Skip if this combination has already been completed\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "\n",
    "                        # tree_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        # final_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_list.txt\"\n",
    "                        tree_path = f\"graphs/result_11.8/bn_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        final_path = f\"graphs/result_11.8/bn_{i}_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        # Check if paths exist; skip if they don't\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree file (assuming the sample index isn't needed)\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate the coalescence time for each sample in the file\n",
    "                        Js = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "\n",
    "                            compute_subtree_sizes(tree)\n",
    "\n",
    "                            for node in tree.traverse():\n",
    "                                compute_balance_scores(node)\n",
    "\n",
    "                            J1 = compute_normalized_balance_index(tree)\n",
    "\n",
    "                            Js.append(J1)\n",
    "                            # print(sample_idx)\n",
    "\n",
    "                        # Calculate mean and variance across all samples\n",
    "                        mean_Js = np.mean(Js)\n",
    "                        variance_Js = np.var(Js)\n",
    "\n",
    "                        # Append results to the data dictionary\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        data['Js'].append(np.mean(mean_Js))\n",
    "                        data['variance_Js'].append(np.var(mean_Js))\n",
    "\n",
    "\n",
    "                        # Update progress bar after each combination\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        # Save a checkpoint after every `checkpoint_interval` iterations\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    # Final save: Create a DataFrame and save as the final file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "# Call the function to write the stats to a pandas DataFrame file with checkpointing\n",
    "calculate_coalescence_df_with_progress_and_saves(\"Js_bn_9.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_subtree_sizes(node):\n",
    "    \"\"\"Recursively calculates the size of each subtree.\"\"\"\n",
    "    if not node.children:\n",
    "        node.size = 1\n",
    "        return 1\n",
    "    \n",
    "    size = 1 + sum(calculate_subtree_sizes(child) for child in node.children)\n",
    "    node.size = size  # Store size in node attribute\n",
    "    return size\n",
    "\n",
    "def get_relative_abundances(node):\n",
    "    \"\"\"Computes relative subtree sizes for Hill number calculations.\"\"\"\n",
    "    total_size = node.size\n",
    "    abundances = [child.size / total_size for child in node.children]\n",
    "    return abundances\n",
    "\n",
    "def hill_number(root, q):\n",
    "    \"\"\"Calculates the Hill number of order q for the given tree.\"\"\"\n",
    "    calculate_subtree_sizes(root)\n",
    "    abundances = get_relative_abundances(root)\n",
    "    \n",
    "    if q == 1:\n",
    "        # Shannon entropy-based diversity (q = 1) using exp(sum p log p)\n",
    "        return np.exp(-sum(p * np.log(p) for p in abundances if p > 0))\n",
    "    \n",
    "    return (sum(p ** q for p in abundances if p > 0)) ** (1 / (1 - q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing paths: graphs/result_11.8/bn_0_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_0_mu0.001_s0.1_list.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times: 100%|██████████| 21/21 [01:12<00:00,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing paths: graphs/result_11.8/bn_10_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_10_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_11_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_11_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_12_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_12_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_13_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_13_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_14_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_14_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_15_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_15_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_16_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_16_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_17_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_17_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_18_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_18_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_19_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_19_mu0.001_s0.1_list.txt\n",
      "Skipping missing paths: graphs/result_11.8/bn_20_mu0.001_s0.1_tree.txt, graphs/result_11.8/bn_20_mu0.001_s0.1_list.txt\n",
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_coalescence_df_with_progress_and_saves(output_file, checkpoint_interval=50):\n",
    "    \"\"\"Calculate mean and variance of coalescence times with progress bar and periodic saves.\n",
    "\n",
    "    Args:\n",
    "        output_file (str): Path to the final output file (Pandas DataFrame saved as a pickle file).\n",
    "        checkpoint_interval (int): Number of iterations after which to save a temporary file.\n",
    "    \"\"\"\n",
    "    ks = [3, 4, 6]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 50\n",
    "    num_samples = 20  # Number of samples per file\n",
    "    iterations = 200 # Number of coalescence calculations per sample\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'Js': [], 'variance_Js': [],}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    # Calculate the total number of combinations for the progress bar\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "                        # Skip if this combination has already been completed\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "\n",
    "                        # tree_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        # final_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_list.txt\"\n",
    "                        # tree_path = f\"graphs/result_11.8/bn_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        # final_path = f\"graphs/result_11.8/bn_{i}_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        tree_path = f\"graphs/result_5.16/{k}_regular_{i}_m{mu}_s{s}.txt_tree.txt\"\n",
    "                        final_path = f\"graphs/result_5.16/{k}_regular_{i}_m{mu}_s{s}.txt_list.txt\"\n",
    "\n",
    "                        # Check if paths exist; skip if they don't\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree file (assuming the sample index isn't needed)\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate the coalescence time for each sample in the file\n",
    "                        Hills = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "\n",
    "                            Hill = hill_number(tree, 1)\n",
    "\n",
    "                            Hills.append(Hill)\n",
    "                            # print(sample_idx)\n",
    "                        # Calculate mean and variance across all samples\n",
    "                        mean_Hills = np.mean(Hills)\n",
    "                        variance_Hills = np.var(Hills)\n",
    "\n",
    "                        # Append results to the data dictionary\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        data['Js'].append(np.mean(mean_Hills))\n",
    "                        data['variance_Js'].append(np.var(mean_Hills))\n",
    "\n",
    "\n",
    "                        # Update progress bar after each combination\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        # Save a checkpoint after every `checkpoint_interval` iterations\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    # Final save: Create a DataFrame and save as the final file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "# Call the function to write the stats to a pandas DataFrame file with checkpointing\n",
    "calculate_coalescence_df_with_progress_and_saves(\"Hills_regular_stoch_50.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tree_metrics(root):\n",
    "    from collections import deque\n",
    "\n",
    "    # Tree size: Total number of nodes\n",
    "    def get_tree_size(node):\n",
    "        if not node:\n",
    "            return 0\n",
    "        return 1 + sum(get_tree_size(child) for child in node.children)\n",
    "\n",
    "    # Tree height: Maximum depth of the tree\n",
    "    def get_tree_height(node):\n",
    "        if not node:\n",
    "            return 0\n",
    "        return 1 + max((get_tree_height(child) for child in node.children), default=0)\n",
    "\n",
    "    # Tree width: Maximum number of nodes at any level\n",
    "    def get_tree_width(node):\n",
    "        if not node:\n",
    "            return 0\n",
    "        queue = deque([(node, 0)])  # (node, level)\n",
    "        level_count = {}\n",
    "        while queue:\n",
    "            current, level = queue.popleft()\n",
    "            level_count[level] = level_count.get(level, 0) + 1\n",
    "            for child in current.children:\n",
    "                queue.append((child, level + 1))\n",
    "        return sum(level_count.values()) / len(level_count) if level_count else 0\n",
    "\n",
    "    # Average terminal branch length\n",
    "    def get_average_terminal_branch_length(node):\n",
    "        total_terminal_length = 0\n",
    "        leaf_count = 0\n",
    "\n",
    "        def traverse(node):\n",
    "            nonlocal total_terminal_length, leaf_count\n",
    "            for child in node.children:\n",
    "                if not child.children:  # It's a leaf\n",
    "                    total_terminal_length += child.dist\n",
    "                    leaf_count += 1\n",
    "                else:\n",
    "                    traverse(child)\n",
    "\n",
    "        traverse(node)\n",
    "\n",
    "        if leaf_count == 0:\n",
    "            return 0\n",
    "        return total_terminal_length / leaf_count\n",
    "\n",
    "    # tree_size = get_tree_size(root)\n",
    "    # tree_height = get_tree_height(root)\n",
    "    tree_width = get_tree_width(root)\n",
    "    # avg_terminal_branch_length = get_average_terminal_branch_length(root)\n",
    "\n",
    "    # return {\n",
    "    #     \"tree_size\": tree_size,\n",
    "    #     \"tree_width\": tree_width,\n",
    "    #     \"tree_height\": tree_height,\n",
    "    #     \"avg_terminal_branch_length\": avg_terminal_branch_length\n",
    "    # }\n",
    "    return {\n",
    "        \"tree_width\": tree_width,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  25%|██▌       | 50/200 [11:46<37:37, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  50%|█████     | 100/200 [24:27<26:09, 15.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times:  75%|███████▌  | 150/200 [37:07<12:29, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coalescence Times: 100%|██████████| 200/200 [49:46<00:00, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at iteration 200\n",
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_coalescence_df_with_progress_and_saves(output_file, checkpoint_interval=50):\n",
    "    \"\"\"Calculate mean and variance of coalescence times with progress bar and periodic saves.\n",
    "\n",
    "    Args:\n",
    "        output_file (str): Path to the final output file (Pandas DataFrame saved as a pickle file).\n",
    "        checkpoint_interval (int): Number of iterations after which to save a temporary file.\n",
    "    \"\"\"\n",
    "    ks = [3, 4, 6, 10]\n",
    "    mus = [0.001]\n",
    "    # mus = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "    ss = [0.1]#, 0.01, 0, -0.01]\n",
    "    repetitions = 50\n",
    "    num_samples = 100  # Number of samples per file\n",
    "    iterations = 200 # Number of coalescence calculations per sample\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    temp_file = output_file + \".tmp\"\n",
    "    if os.path.exists(temp_file):\n",
    "        checkpoint_df = pd.read_pickle(temp_file)\n",
    "        data = checkpoint_df.to_dict(orient='list')\n",
    "        completed_combinations = set(zip(data['k'], data['mu'], data['s'], data['repetition']))\n",
    "        print(\"Resuming from checkpoint.\")\n",
    "    else:\n",
    "        data = {'k': [], 'mu': [], 's': [], 'repetition': [],\n",
    "                'tree_width': []}\n",
    "        completed_combinations = set()\n",
    "\n",
    "    # Calculate the total number of combinations for the progress bar\n",
    "    total_combinations = len(ks) * len(mus) * len(ss) * repetitions\n",
    "    remaining_combinations = total_combinations - len(completed_combinations)\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(total=remaining_combinations, desc='Calculating Coalescence Times') as pbar:\n",
    "        count = 0\n",
    "        for k in ks:\n",
    "            for mu in mus:\n",
    "                for s in ss:\n",
    "                    for i in range(repetitions):\n",
    "                        # Skip if this combination has already been completed\n",
    "                        if (k, mu, s, i) in completed_combinations:\n",
    "                            continue\n",
    "\n",
    "                        tree_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        final_path = f\"graphs/result_11.13/{k}_regular_{i}_mu{mu}_s{s}_list.txt\"\n",
    "                        # tree_path = f\"graphs/result_11.8/sw_{i}_mu{mu}_s{s}_tree.txt\"\n",
    "                        # final_path = f\"graphs/result_11.8/sw_{i}_mu{mu}_s{s}_list.txt\"\n",
    "\n",
    "                        # Check if paths exist; skip if they don't\n",
    "                        if not os.path.exists(tree_path) or not os.path.exists(final_path):\n",
    "                            print(f\"Skipping missing paths: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Load the tree file (assuming the sample index isn't needed)\n",
    "                        tree_samples = count_non_empty_lines(tree_path)\n",
    "                        final_samples = count_non_empty_lines(final_path)\n",
    "                        num_samples = min(tree_samples, final_samples, num_samples)\n",
    "\n",
    "                        if num_samples == 0:\n",
    "                            print(f\"Skipping empty files: {tree_path}, {final_path}\")\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "\n",
    "                        # Calculate the coalescence time for each sample in the file\n",
    "                        tree_size = []\n",
    "                        tree_width = []\n",
    "                        tree_height = []\n",
    "                        terminal_branch_length = []\n",
    "                        for sample_idx in range(num_samples):\n",
    "                            tree_dict = build_tree(tree_path, sample_idx)\n",
    "                            tree = tree_dict[0]\n",
    "\n",
    "                            metrics = calculate_tree_metrics(tree)\n",
    "\n",
    "                            # tree_size.append(metrics[\"tree_size\"])\n",
    "                            tree_width.append(metrics[\"tree_width\"])\n",
    "                            # tree_height.append(metrics[\"tree_height\"]) \n",
    "                            # terminal_branch_length.append(metrics[\"avg_terminal_branch_length\"])\n",
    "                            # print(sample_idx)\n",
    "                        # Calculate mean and variance across all samples\n",
    "                        # mean_tree_size = np.mean(tree_size)\n",
    "                        mean_tree_width = np.mean(tree_width)\n",
    "                        # mean_tree_height = np.mean(tree_height)\n",
    "\n",
    "                        # Append results to the data dictionary\n",
    "                        data['k'].append(k)\n",
    "                        data['mu'].append(mu)\n",
    "                        data['s'].append(s)\n",
    "                        data['repetition'].append(i)\n",
    "                        # data['tree_size'].append(np.mean(mean_tree_size))\n",
    "                        data['tree_width'].append(np.mean(mean_tree_width))\n",
    "                        # data['tree_height'].append(np.mean(mean_tree_height))\n",
    "                        # data['terminal_branch_length'].append(np.mean(terminal_branch_length))\n",
    "\n",
    "                        # Update progress bar after each combination\n",
    "                        pbar.update(1)\n",
    "                        count += 1\n",
    "\n",
    "                        # Save a checkpoint after every `checkpoint_interval` iterations\n",
    "                        if count % checkpoint_interval == 0:\n",
    "                            checkpoint_df = pd.DataFrame(data)\n",
    "                            checkpoint_df.to_pickle(output_file + \".tmp\")\n",
    "                            print(f\"Checkpoint saved at iteration {count}\")\n",
    "\n",
    "    # Final save: Create a DataFrame and save as the final file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(output_file)\n",
    "    print(\"Final results saved.\")\n",
    "\n",
    "# Call the function to write the stats to a pandas DataFrame file with checkpointing\n",
    "calculate_coalescence_df_with_progress_and_saves(\"Width_regular_50.pkl\", checkpoint_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Hills_regular_50.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df31 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHills_regular_50.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df31\n",
      "File \u001b[1;32md:\\Tool\\Anaconda\\envs\\tree\\Lib\\site-packages\\pandas\\io\\pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Tool\\Anaconda\\envs\\tree\\Lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Hills_regular_50.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df31 = pd.read_pickle(\"Hills_regular_50.pkl\")\n",
    "df31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph</th>\n",
       "      <th>mu</th>\n",
       "      <th>s</th>\n",
       "      <th>index</th>\n",
       "      <th>Js</th>\n",
       "      <th>Hill</th>\n",
       "      <th>sackin</th>\n",
       "      <th>mean_coalescence_time</th>\n",
       "      <th>tree_size</th>\n",
       "      <th>tree_width</th>\n",
       "      <th>...</th>\n",
       "      <th>acc</th>\n",
       "      <th>ConnectivityIndex</th>\n",
       "      <th>AlgebraicConnectivity</th>\n",
       "      <th>area</th>\n",
       "      <th>ratio_branch_to_height</th>\n",
       "      <th>ratio_branch_to_size</th>\n",
       "      <th>ratio_sackin_to_size</th>\n",
       "      <th>ratio_sackin_to_height</th>\n",
       "      <th>ratio_sackin_to_area</th>\n",
       "      <th>ratio_sackin_to_Hill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>1.085766</td>\n",
       "      <td>68.794408</td>\n",
       "      <td>1.16770</td>\n",
       "      <td>10005.72</td>\n",
       "      <td>110.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28330.7409</td>\n",
       "      <td>0.496995</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>63.360226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1.085674</td>\n",
       "      <td>72.209340</td>\n",
       "      <td>1.09025</td>\n",
       "      <td>10016.88</td>\n",
       "      <td>110.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556971</td>\n",
       "      <td>28502.7346</td>\n",
       "      <td>0.496810</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.280120</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>66.511078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.081703</td>\n",
       "      <td>70.585114</td>\n",
       "      <td>1.09475</td>\n",
       "      <td>10007.26</td>\n",
       "      <td>111.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748963</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.269001</td>\n",
       "      <td>28736.6292</td>\n",
       "      <td>0.497369</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.273236</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>65.253703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>1.080297</td>\n",
       "      <td>75.577822</td>\n",
       "      <td>1.03860</td>\n",
       "      <td>10000.49</td>\n",
       "      <td>111.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786613</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.103527</td>\n",
       "      <td>29142.5351</td>\n",
       "      <td>0.498218</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.289915</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>69.960217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>1.080507</td>\n",
       "      <td>72.608354</td>\n",
       "      <td>1.16805</td>\n",
       "      <td>10007.53</td>\n",
       "      <td>111.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.841214</td>\n",
       "      <td>29016.0099</td>\n",
       "      <td>0.496282</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.279188</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>67.198407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>bn</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1.105629</td>\n",
       "      <td>67.215759</td>\n",
       "      <td>1.47990</td>\n",
       "      <td>10009.38</td>\n",
       "      <td>116.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.024320</td>\n",
       "      <td>28005.2032</td>\n",
       "      <td>0.496811</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.279182</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>60.794153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>bn</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>1.092483</td>\n",
       "      <td>67.034074</td>\n",
       "      <td>1.33390</td>\n",
       "      <td>10008.48</td>\n",
       "      <td>115.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813978</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.037964</td>\n",
       "      <td>27993.9940</td>\n",
       "      <td>0.496536</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.277413</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>61.359365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>bn</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.089900</td>\n",
       "      <td>67.173369</td>\n",
       "      <td>1.13520</td>\n",
       "      <td>9992.91</td>\n",
       "      <td>114.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806132</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.076205</td>\n",
       "      <td>28158.8628</td>\n",
       "      <td>0.495821</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>0.272807</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>61.632587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>bn</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1.087612</td>\n",
       "      <td>66.916265</td>\n",
       "      <td>1.11840</td>\n",
       "      <td>10017.46</td>\n",
       "      <td>113.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809710</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.153080</td>\n",
       "      <td>28322.8120</td>\n",
       "      <td>0.497115</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.267024</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>61.525849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>bn</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>1.090637</td>\n",
       "      <td>65.239713</td>\n",
       "      <td>1.12330</td>\n",
       "      <td>10007.11</td>\n",
       "      <td>112.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785354</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.290996</td>\n",
       "      <td>28463.8900</td>\n",
       "      <td>0.497329</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.258631</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>59.817999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    graph     mu    s  index        Js      Hill     sackin  \\\n",
       "0      pa  0.001  0.1      1  0.000233  1.085766  68.794408   \n",
       "1      pa  0.001  0.1      2  0.000229  1.085674  72.209340   \n",
       "2      pa  0.001  0.1      3  0.000227  1.081703  70.585114   \n",
       "3      pa  0.001  0.1      4  0.000223  1.080297  75.577822   \n",
       "4      pa  0.001  0.1      5  0.000224  1.080507  72.608354   \n",
       "..    ...    ...  ...    ...       ...       ...        ...   \n",
       "280    bn  0.001  0.1      5  0.000265  1.105629  67.215759   \n",
       "281    bn  0.001  0.1      6  0.000263  1.092483  67.034074   \n",
       "282    bn  0.001  0.1      7  0.000253  1.089900  67.173369   \n",
       "283    bn  0.001  0.1      8  0.000244  1.087612  66.916265   \n",
       "284    bn  0.001  0.1      9  0.000239  1.090637  65.239713   \n",
       "\n",
       "     mean_coalescence_time  tree_size  tree_width  ...       acc  \\\n",
       "0                  1.16770   10005.72      110.49  ...  0.762193   \n",
       "1                  1.09025   10016.88      110.57  ...  0.799076   \n",
       "2                  1.09475   10007.26      111.24  ...  0.748963   \n",
       "3                  1.03860   10000.49      111.79  ...  0.786613   \n",
       "4                  1.16805   10007.53      111.57  ...  0.805082   \n",
       "..                     ...        ...         ...  ...       ...   \n",
       "280                1.47990   10009.38      116.32  ...  0.788750   \n",
       "281                1.33390   10008.48      115.85  ...  0.813978   \n",
       "282                1.13520    9992.91      114.36  ...  0.806132   \n",
       "283                1.11840   10017.46      113.02  ...  0.809710   \n",
       "284                1.12330   10007.11      112.84  ...  0.785354   \n",
       "\n",
       "     ConnectivityIndex  AlgebraicConnectivity        area  \\\n",
       "0                  0.0               0.000000  28330.7409   \n",
       "1                  2.0               0.556971  28502.7346   \n",
       "2                  3.0               1.269001  28736.6292   \n",
       "3                  4.0               2.103527  29142.5351   \n",
       "4                  5.0               2.841214  29016.0099   \n",
       "..                 ...                    ...         ...   \n",
       "280                5.0               0.024320  28005.2032   \n",
       "281                5.0               0.037964  27993.9940   \n",
       "282                5.0               0.076205  28158.8628   \n",
       "283                5.0               0.153080  28322.8120   \n",
       "284                5.0               0.290996  28463.8900   \n",
       "\n",
       "     ratio_branch_to_height  ratio_branch_to_size  ratio_sackin_to_size  \\\n",
       "0                  0.496995              0.012736              0.006876   \n",
       "1                  0.496810              0.012785              0.007209   \n",
       "2                  0.497369              0.012839              0.007053   \n",
       "3                  0.498218              0.012987              0.007557   \n",
       "4                  0.496282              0.012897              0.007255   \n",
       "..                      ...                   ...                   ...   \n",
       "280                0.496811              0.011950              0.006715   \n",
       "281                0.496536              0.011988              0.006698   \n",
       "282                0.495821              0.012217              0.006722   \n",
       "283                0.497115              0.012436              0.006680   \n",
       "284                0.497329              0.012536              0.006519   \n",
       "\n",
       "     ratio_sackin_to_height  ratio_sackin_to_area  ratio_sackin_to_Hill  \n",
       "0                  0.268298              0.002428             63.360226  \n",
       "1                  0.280120              0.002533             66.511078  \n",
       "2                  0.273236              0.002456             65.253703  \n",
       "3                  0.289915              0.002593             69.960217  \n",
       "4                  0.279188              0.002502             67.198407  \n",
       "..                      ...                   ...                   ...  \n",
       "280                0.279182              0.002400             60.794153  \n",
       "281                0.277413              0.002395             61.359365  \n",
       "282                0.272807              0.002386             61.632587  \n",
       "283                0.267024              0.002363             61.525849  \n",
       "284                0.258631              0.002292             59.817999  \n",
       "\n",
       "[285 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"combined_df.pkl\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
